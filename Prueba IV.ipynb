{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: root@mysql'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "mysql+pymysql://root:12345678@localhost/mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost/mysql\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE DATABASE prueba;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost/mysql\n",
      "0 rows affected.\n",
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS prueba.usuario (\n",
    "  id varchar(50) NOT NULL,\n",
    "  fechaCreacion datetime NOT NULL,\n",
    "  nombre varchar(140) NOT NULL,\n",
    "  ubicacion varchar(140) NOT NULL,\n",
    "  followersCount integer NOT NULL,\n",
    "  friendsCount integer NOT NULL,\n",
    "  favouritesCount integer NOT NULL,  \n",
    "  PRIMARY KEY (id)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS prueba.tweet (\n",
    "  id varchar(50) NOT NULL,\n",
    "  idUsuario varchar(50) NOT NULL,\n",
    "  fechaCreacion datetime NOT NULL,\n",
    "  texto varchar(300) NOT NULL, \n",
    "  lang varchar(50) NOT NULL,\n",
    "  PRIMARY KEY (id),\n",
    "  FOREIGN KEY (idUsuario) REFERENCES usuario(id) ON UPDATE \n",
    "  CASCADE ON DELETE CASCADE\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost/mysql\n",
      "2 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>TABLE_NAME</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>usuario</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('tweet',), ('usuario',)]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "select table_name from information_schema.tables where table_schema='prueba';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "# Clase User\n",
    "class User(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.id = \"\"\n",
    "        self.created = \"\"\n",
    "        self.name = \"\"\n",
    "        self.location = \"\"\n",
    "        self.followersCount = 0\n",
    "        self.friendsCount= 0\n",
    "        self.favouritesCount = 0\n",
    "\n",
    "    def __init__(self,id,fechaCreacion,nombre,ubicacion,followersCount,friendsCount,favouritesCount):\n",
    "        self.id = id\n",
    "        self.fechaCreacion = fechaCreacion\n",
    "        self.nombre = nombre\n",
    "        self.ubicacion = ubicacion\n",
    "        self.followersCount = followersCount\n",
    "        self.friendsCount = friendsCount\n",
    "        self.favouritesCount = favouritesCount        \n",
    "    \n",
    "    def getId(self):\n",
    "        return self.id\n",
    "    \n",
    "    \n",
    "    def agregarUsuario(self):\n",
    "        try:\n",
    "            connection = pymysql.connect(host = 'localhost', user = 'root',\n",
    "                                         password = '12345678', db = 'prueba', charset = 'utf8')\n",
    "            with connection.cursor() as cursor:\n",
    "                sentenciaSQL = \"INSERT INTO prueba.usuario(id,fechaCreacion,nombre,ubicacion,\"+\\\n",
    "                \"followersCount,friendsCount,favouritesCount) VALUES \"+\\\n",
    "                \"(%s,%s,%s,%s,%s,%s,%s)\"\n",
    "                cursor.execute(sentenciaSQL, (str(self.id),\n",
    "                                              self.fechaCreacion,\n",
    "                                              str(self.nombre),\n",
    "                                              str(self.ubicacion),\n",
    "                                              self.followersCount,\n",
    "                                              self.friendsCount,\n",
    "                                              self.favouritesCount))                \n",
    "                connection.commit()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Error on_data: %s\" % str(e))\n",
    "        finally:\n",
    "            connection.close()\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"'{0}', '{1}', '{2}', '{3}', '{4}', '{5}', '{6}'\".format(self.id,\n",
    "                                                                        self.fechaCreacion, \n",
    "                                                                        self.nombre,\n",
    "                                                                        self.ubicacion, \n",
    "                                                                        self.followersCount,\n",
    "                                                                        self.friendsCount, \n",
    "                                                                        self.favouritesCount)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet(object):\n",
    "    \n",
    "    #metodo para inicializar la clase    \n",
    "    def __init__(self):\n",
    "        self.id = \"\"\n",
    "        self.fechaCreacion = \"\"\n",
    "        self.contenido = \"\"\n",
    "        self.lang= \"\"\n",
    "        self.user = None\n",
    "        \n",
    "    def __init__(self,id,fechaCreacion,contenido,lang,user):\n",
    "        self.id = id\n",
    "        self.fechaCreacion = fechaCreacion\n",
    "        self.contenido = contenido\n",
    "        self.lang = lang\n",
    "        self.user = user        \n",
    " \n",
    "    def agregarTweet(self):\n",
    "        #Conexi√≥n a base de datos\n",
    "        try:\n",
    "            connection = pymysql.connect(host = 'localhost', user = 'root',\n",
    "                                         password = '12345678', db = 'prueba', charset = 'utf8')\n",
    "            with connection.cursor() as cursor:\n",
    "                sentenciaSQL=(\"INSERT INTO prueba.tweet(id,fechaCreacion,texto,lang,idUsuario) \"+\\\n",
    "                              \"VALUES (%s,%s,%s,%s,%s)\")\n",
    "                cursor.execute(sentenciaSQL, (str(self.id),\n",
    "                                              self.fechaCreacion, \n",
    "                                              str(self.contenido), \n",
    "                                              str(self.lang),\n",
    "                                              str(self.user.getId())))                \n",
    "                connection.commit()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Error on_data: %s\" % str(e))\n",
    "        finally:\n",
    "            connection.close()   \n",
    "        \n",
    "\n",
    "    def __str__(self):\n",
    "         return \"'{0}', '{1}', '{2}', '{3}', '{4}'\".format(self.id,\n",
    "                                                           self.fechaCreacion,\n",
    "                                                           self.lang,\n",
    "                                                           self.contenido,\n",
    "                                                           self.user)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "from datetime import datetime\n",
    "\n",
    "class UtilTwitter(object):\n",
    "    \n",
    "    emojin_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U00002600-\\U000027BF\"\n",
    "                           u\"\\U0001f300-\\U0001f64F\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "        \n",
    "    @staticmethod\n",
    "    def format_datetime(text):\n",
    "        datetime_object = datetime.strptime(text, '%a %b %d %H:%M:%S %z %Y')\n",
    "        return datetime_object.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_emoticon(text):        \n",
    "        free_emoticon = ''.join(c for c in text if c not in emoji.UNICODE_EMOJI)\n",
    "        return UtilTwitter.emojin_pattern.sub(r'', free_emoticon)\n",
    "    \n",
    "    @staticmethod\n",
    "    def clear_text(text:str):        \n",
    "        if text is None:\n",
    "            return \"Indefinido\"\n",
    "        elif text.strip() == \"\":\n",
    "            return \"Indefinido\"\n",
    "        else:\n",
    "            return \" \".join(re.findall(\"[a-zA-Z]+\", text))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.004s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class UtilTwitterTest(unittest.TestCase):\n",
    "    \n",
    "    def test_format_datetime(self):        \n",
    "        self.assertEqual(\"2018-06-29 06:47:19\",UtilTwitter.format_datetime(\"Fri Jun 29 06:47:19 +0000 2018\"))\n",
    "\n",
    "    def test_clear_text(self):\n",
    "        self.assertEqual(\"nadya\", UtilTwitter.clear_text(\"nadyaü•Ä\"))\n",
    "        \n",
    "    def test_clear_none(self):\n",
    "        self.assertEqual(\"Indefinido\", UtilTwitter.clear_text(None))\n",
    "    \n",
    "    def test_clear_vacio(self):\n",
    "        self.assertEqual(\"Indefinido\", UtilTwitter.clear_text(\"   \"))\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "import time\n",
    "import json\n",
    "\n",
    "class TwitterListener(tweepy.StreamListener):\n",
    "    \"\"\"Custom StreamListener for streaming data.\"\"\"\n",
    "    def __init__(self, time_limit=60):\n",
    "        self.start_time = time.time()\n",
    "        self.limit = time_limit       \n",
    "    \n",
    "    \n",
    "    def on_data(self, tweet_json):\n",
    "        \n",
    "        if (time.time() - self.start_time) < self.limit:        \n",
    "            tweet_json  =  tweet_json.encode('utf8')\n",
    "            decoded = json.loads(tweet_json)\n",
    "            \n",
    "            try:\n",
    "                #Obtener datos Usuario\n",
    "                userjson = decoded.get('user')\n",
    "                id_user = userjson.get('id')\n",
    "                created_user = UtilTwitter.format_datetime(userjson.get('created_at'))\n",
    "                name_user = UtilTwitter.clear_text(userjson.get('name'))\n",
    "                location_user = UtilTwitter.clear_text(userjson.get('location'))\n",
    "                followersCount_user = userjson.get('followers_count')\n",
    "                friendsCount_user = userjson.get('friends_count')\n",
    "                favouritesCount_user = userjson.get('favourites_count')\n",
    "                #Obtener datos Tweet\n",
    "                id_tweet = decoded.get('id_str')                \n",
    "                text_tweet = UtilTwitter.remove_emoticon(decoded.get('text'))\n",
    "                created_tweet = UtilTwitter.format_datetime(decoded.get('created_at'))\n",
    "                lang_tweet = userjson.get('lang')\n",
    "                \n",
    "                oUser = User(id_user,created_user,name_user,location_user,followersCount_user,friendsCount_user,\n",
    "                             favouritesCount_user)\n",
    "\n",
    "                print(oUser)\n",
    "                \n",
    "                oTweet = Tweet(id_tweet, created_tweet, text_tweet, lang_tweet, oUser)\n",
    "                \n",
    "                print(oTweet)\n",
    "                \n",
    "                oUser.agregarUsuario()\n",
    "                oTweet.agregarTweet()                \n",
    "\n",
    "            except BaseException as e:\n",
    "                print(\"Error on_data: %s\" % str(e))\n",
    "                time.sleep(5)\n",
    "            return True\n",
    "        else:\n",
    "            return False #Kill current stream\n",
    "        \n",
    "    def on_error(self, status):\n",
    "        print(\"Error status: \" + str(status))\n",
    "        return True\n",
    "\n",
    "    def on_timeout(self):\n",
    "        print ('Timeout...')\n",
    "        return True # Don't kill the stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "\n",
    "class ExtraccionTwitterCtrl(object):\n",
    "#Credenciales de cuenta Twitter\n",
    "    CONSUMER_KEY = 'GAj4aLmKWjk9Qi7FSp0kqg6y8'\n",
    "    CONSUMER_SECRET = 'zfpgsQBq1pPDO7BeHPb9IGqO6tuzH7Jru5yk9d3sCr8Onqodor'\n",
    "    ACCESS_TOKEN  = '372079997-tPaPJG8Grk03nfclH7gLzZKxgdyFE6rnWlQFDMzG'\n",
    "    ACCESS_SECRET  = 'aCgTryAToksZyJTUwdad0atzeNuWO4poQEAgsUXWeYI2V'\n",
    "\n",
    "    def __init__(self):\n",
    "        # Autenticaci√≥n\n",
    "        self.auth = OAuthHandler(self.CONSUMER_KEY, self.CONSUMER_SECRET)\n",
    "        self.auth.set_access_token(self.ACCESS_TOKEN, self.ACCESS_SECRET)\n",
    "        \n",
    "    def filterByText(self, list_tag, time_limit):\n",
    "        print(\"Inicio de filterByText\\n\")\n",
    "        try:            \n",
    "            twitter_stream = tweepy.streaming.Stream(self.auth, TwitterListener(time_limit))\n",
    "            twitter_stream.filter(track=hash_tag)\n",
    "        except (KeyboardInterrupt, SystemExit):\n",
    "            print(\"Parar proceso de extracci√≥n\\n\")\n",
    "        print(\"Fin de filterByText\\n\")\n",
    "        \n",
    "    def filterByLocations(self, locations, time_limit):\n",
    "        print(\"Inificio de filterByLocations\\n\")\n",
    "        try:            \n",
    "            twitter_stream = tweepy.streaming.Stream(self.auth, TwitterListener(time_limit))\n",
    "            twitter_stream.filter(locations = peru)\n",
    "        except (KeyboardInterrupt, SystemExit):\n",
    "            print(\"Parar proceso de extracci√≥n\\n\")\n",
    "        print(\"Fin de filterByLocations\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener tweets sobre tema: Alan\n",
    "hash_tag=['Alan Garcia']\n",
    "#hash_tag=['Marca']\n",
    "\n",
    "# Obtener tweets generados por pa√≠z\n",
    "france=[-5.1406, 41.333740, 9.559320, 51.089062]\n",
    "spain =[-4.042280, 40.611900, -4.023130,40.630329]\n",
    "italy=[-96.901863,32.171291, -96.866524, 32.204861]\n",
    "germany = [5.866240,47.270210, 15.042050,55.058140]\n",
    "peru = [-81.326736,-18.34972,  -68.677979, -0.01297]\n",
    "senegal =[-17.535231,12.30727, -11.35588,16.691629]\n",
    "costaMarfil =[-8.5993,4.35706, -2.49489,10.73664]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inificio de filterByLocations\n",
      "\n",
      "'939125362403020800', '2017-12-08 13:31:49', 'AASANA', 'Indefinido', '249', '527', '1322'\n",
      "'1064626594717859841', '2018-11-19 21:08:54', 'es', 'Nota De Prensa. https://t.co/ZLIcoGJxXa', ''939125362403020800', '2017-12-08 13:31:49', 'AASANA', 'Indefinido', '249', '527', '1322''\n",
      "'301717558', '2011-05-19 23:05:13', 'Gustavo Alonso', 'Lima Per', '210', '1217', '2790'\n",
      "'1064626598052270086', '2018-11-19 21:08:55', 'es', '@aytinoco Puedes agravar la lesi√≥n, ten cuidado.', ''301717558', '2011-05-19 23:05:13', 'Gustavo Alonso', 'Lima Per', '210', '1217', '2790''\n",
      "'208261603', '2010-10-26 23:33:17', 'Markos BernAL', 'LIMA', '139', '95', '3702'\n",
      "'1064626600082329606', '2018-11-19 21:08:55', 'es', 'Let the world know that in Peru there is a dictatorship disguised as democracy\n",
      "#VizcarraDictador', ''208261603', '2010-10-26 23:33:17', 'Markos BernAL', 'LIMA', '139', '95', '3702''\n",
      "'946228417518821377', '2017-12-28 03:56:49', 'Federico Clemente', 'Indefinido', '351', '2519', '5294'\n",
      "'1064626626695176192', '2018-11-19 21:09:02', 'es', 'Fintech peruana Tasatop incursiona en M√©xico para captar a ahorristas\n",
      "\"Para el primer a√±o de operaciones esperamos‚Ä¶ https://t.co/xOWbXmjdo0', ''946228417518821377', '2017-12-28 03:56:49', 'Federico Clemente', 'Indefinido', '351', '2519', '5294''\n",
      "'304875504', '2011-05-25 07:56:05', 'Brunon', 'Indefinido', '2686', '2102', '66247'\n",
      "'1064626659826024450', '2018-11-19 21:09:10', 'pt', '@kevinnunesc Tadinhos kkkkk no m√°ximo nudes e likes, n√£o passa disso.', ''304875504', '2011-05-25 07:56:05', 'Brunon', 'Indefinido', '2686', '2102', '66247''\n",
      "Fin de filterByLocations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oExtraccion = ExtraccionTwitterCtrl()\n",
    "oExtraccion.filterByLocations(hash_tag, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost/mysql\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>id</th>\n",
       "        <th>fechaCreacion</th>\n",
       "        <th>nombre</th>\n",
       "        <th>ubicacion</th>\n",
       "        <th>followersCount</th>\n",
       "        <th>friendsCount</th>\n",
       "        <th>favouritesCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>208261603</td>\n",
       "        <td>2010-10-26 23:33:17</td>\n",
       "        <td>Markos BernAL</td>\n",
       "        <td>LIMA</td>\n",
       "        <td>139</td>\n",
       "        <td>95</td>\n",
       "        <td>3702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>301717558</td>\n",
       "        <td>2011-05-19 23:05:13</td>\n",
       "        <td>Gustavo Alonso</td>\n",
       "        <td>Lima Per</td>\n",
       "        <td>210</td>\n",
       "        <td>1217</td>\n",
       "        <td>2790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>304875504</td>\n",
       "        <td>2011-05-25 07:56:05</td>\n",
       "        <td>Brunon</td>\n",
       "        <td>Indefinido</td>\n",
       "        <td>2686</td>\n",
       "        <td>2102</td>\n",
       "        <td>66247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>939125362403020800</td>\n",
       "        <td>2017-12-08 13:31:49</td>\n",
       "        <td>AASANA</td>\n",
       "        <td>Indefinido</td>\n",
       "        <td>249</td>\n",
       "        <td>527</td>\n",
       "        <td>1322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>946228417518821377</td>\n",
       "        <td>2017-12-28 03:56:49</td>\n",
       "        <td>Federico Clemente</td>\n",
       "        <td>Indefinido</td>\n",
       "        <td>351</td>\n",
       "        <td>2519</td>\n",
       "        <td>5294</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('208261603', datetime.datetime(2010, 10, 26, 23, 33, 17), 'Markos BernAL', 'LIMA', 139, 95, 3702),\n",
       " ('301717558', datetime.datetime(2011, 5, 19, 23, 5, 13), 'Gustavo Alonso', 'Lima Per', 210, 1217, 2790),\n",
       " ('304875504', datetime.datetime(2011, 5, 25, 7, 56, 5), 'Brunon', 'Indefinido', 2686, 2102, 66247),\n",
       " ('939125362403020800', datetime.datetime(2017, 12, 8, 13, 31, 49), 'AASANA', 'Indefinido', 249, 527, 1322),\n",
       " ('946228417518821377', datetime.datetime(2017, 12, 28, 3, 56, 49), 'Federico Clemente', 'Indefinido', 351, 2519, 5294)]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "select * from prueba.usuario limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost/mysql\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>id</th>\n",
       "        <th>idUsuario</th>\n",
       "        <th>fechaCreacion</th>\n",
       "        <th>texto</th>\n",
       "        <th>lang</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1064626594717859841</td>\n",
       "        <td>939125362403020800</td>\n",
       "        <td>2018-11-19 21:08:54</td>\n",
       "        <td>Nota De Prensa. https://t.co/ZLIcoGJxXa</td>\n",
       "        <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1064626598052270086</td>\n",
       "        <td>301717558</td>\n",
       "        <td>2018-11-19 21:08:55</td>\n",
       "        <td>@aytinoco Puedes agravar la lesi√≥n, ten cuidado.</td>\n",
       "        <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1064626600082329606</td>\n",
       "        <td>208261603</td>\n",
       "        <td>2018-11-19 21:08:55</td>\n",
       "        <td>Let the world know that in Peru there is a dictatorship disguised as democracy<br>#VizcarraDictador</td>\n",
       "        <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1064626626695176192</td>\n",
       "        <td>946228417518821377</td>\n",
       "        <td>2018-11-19 21:09:02</td>\n",
       "        <td>Fintech peruana Tasatop incursiona en M√©xico para captar a ahorristas<br>&quot;Para el primer a√±o de operaciones esperamos‚Ä¶ https://t.co/xOWbXmjdo0</td>\n",
       "        <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1064626659826024450</td>\n",
       "        <td>304875504</td>\n",
       "        <td>2018-11-19 21:09:10</td>\n",
       "        <td>@kevinnunesc Tadinhos kkkkk no m√°ximo nudes e likes, n√£o passa disso.</td>\n",
       "        <td>pt</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('1064626594717859841', '939125362403020800', datetime.datetime(2018, 11, 19, 21, 8, 54), 'Nota De Prensa. https://t.co/ZLIcoGJxXa', 'es'),\n",
       " ('1064626598052270086', '301717558', datetime.datetime(2018, 11, 19, 21, 8, 55), '@aytinoco Puedes agravar la lesi√≥n, ten cuidado.', 'es'),\n",
       " ('1064626600082329606', '208261603', datetime.datetime(2018, 11, 19, 21, 8, 55), 'Let the world know that in Peru there is a dictatorship disguised as democracy\\n#VizcarraDictador', 'es'),\n",
       " ('1064626626695176192', '946228417518821377', datetime.datetime(2018, 11, 19, 21, 9, 2), 'Fintech peruana Tasatop incursiona en M√©xico para captar a ahorristas\\n\"Para el primer a√±o de operaciones esperamos‚Ä¶ https://t.co/xOWbXmjdo0', 'es'),\n",
       " ('1064626659826024450', '304875504', datetime.datetime(2018, 11, 19, 21, 9, 10), '@kevinnunesc Tadinhos kkkkk no m√°ximo nudes e likes, n√£o passa disso.', 'pt')]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "select * from prueba.tweet limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost/mysql\n",
      "4 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>DATA_TYPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>varchar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>varchar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>varchar</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('varchar',), ('varchar',), ('datetime',), ('varchar',)]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT DATA_TYPE \n",
    "FROM INFORMATION_SCHEMA.COLUMNS\n",
    "WHERE TABLE_SCHEMA = 'dbtwitter'\n",
    "AND TABLE_NAME = 'tweet';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>idUsuario</th>\n",
       "      <th>fechaCreacion</th>\n",
       "      <th>texto</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1064626594717859841</td>\n",
       "      <td>939125362403020800</td>\n",
       "      <td>2018-11-19 21:08:54</td>\n",
       "      <td>Nota De Prensa. https://t.co/ZLIcoGJxXa</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1064626598052270086</td>\n",
       "      <td>301717558</td>\n",
       "      <td>2018-11-19 21:08:55</td>\n",
       "      <td>@aytinoco Puedes agravar la lesi√≥n, ten cuidado.</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1064626600082329606</td>\n",
       "      <td>208261603</td>\n",
       "      <td>2018-11-19 21:08:55</td>\n",
       "      <td>Let the world know that in Peru there is a dic...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1064626626695176192</td>\n",
       "      <td>946228417518821377</td>\n",
       "      <td>2018-11-19 21:09:02</td>\n",
       "      <td>Fintech peruana Tasatop incursiona en M√©xico p...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           idUsuario       fechaCreacion  \\\n",
       "0  1064626594717859841  939125362403020800 2018-11-19 21:08:54   \n",
       "1  1064626598052270086           301717558 2018-11-19 21:08:55   \n",
       "2  1064626600082329606           208261603 2018-11-19 21:08:55   \n",
       "3  1064626626695176192  946228417518821377 2018-11-19 21:09:02   \n",
       "\n",
       "                                               texto lang  \n",
       "0            Nota De Prensa. https://t.co/ZLIcoGJxXa   es  \n",
       "1   @aytinoco Puedes agravar la lesi√≥n, ten cuidado.   es  \n",
       "2  Let the world know that in Peru there is a dic...   es  \n",
       "3  Fintech peruana Tasatop incursiona en M√©xico p...   es  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "tweetSchema= {'fechaCreacion': {'format': '%Y-%m-%d %H:%M:%S'}}\n",
    "\n",
    "myconnection = pymysql.connect(host = 'localhost', user = 'root',\n",
    "                               password = '12345678', db = 'prueba', \n",
    "                               charset = 'utf8')\n",
    "df_db = None\n",
    "try:\n",
    "    df_db = pd.read_sql(sql='SELECT * FROM tweet WHERE lang=\"es\";', con = myconnection, parse_dates = tweetSchema)\n",
    "finally:\n",
    "    myconnection.close()\n",
    "\n",
    "df_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       object\n",
       "idUsuario                object\n",
       "fechaCreacion    datetime64[ns]\n",
       "texto                    object\n",
       "lang                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_db.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_texto = df_db[\"texto\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stop_words = stopwords.words('spanish')\n",
    "stop_words.extend([\"rt\", \"aun\", \"oe\"])\n",
    "exclude = string.punctuation\n",
    "exclude = exclude + \"¬ø\"\n",
    "\n",
    "lemma = SnowballStemmer('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\"\"\"def remove_number(list_text):\n",
    "    return ''.join([i for i in text if not i.isdigit()])\"\"\"\n",
    "\n",
    "def remove_three_dots(list_text):\n",
    "    return [re.sub(r\"[a-zA-Z]+(\\‚Ä¶‚Ä¶|\\‚Ä¶)$\", \" \", texto) for texto in list_text]\n",
    "\n",
    "def remove_url(list_text):\n",
    "    return [re.sub(r\"http\\S+\", \"\", texto).strip() for texto in list_text]\n",
    "\n",
    "def remove_breakline(list_text):\n",
    "    return [re.sub('\\s+', ' ', texto) for texto in list_text]\n",
    "\n",
    "def remove_single_quotes(list_text):\n",
    "    return [re.sub(\"\\'\", \"\", texto) for texto in list_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nota De Prensa. https://t.co/ZLIcoGJxXa', '@aytinoco Puedes agravar la lesi√≥n, ten cuidado.', 'Let the world know that in Peru there is a dictatorship disguised as democracy\\n#VizcarraDictador', 'Fintech peruana Tasatop incursiona en M√©xico para captar a ahorristas\\n\"Para el primer a√±o de operaciones esperamos‚Ä¶ https://t.co/xOWbXmjdo0']\n"
     ]
    }
   ],
   "source": [
    "data = df_db.texto.values.tolist()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['nota', 'de', 'prensa'], ['aytinoco', 'puedes', 'agravar', 'la', 'lesion', 'ten', 'cuidado'], ['let', 'the', 'world', 'know', 'that', 'in', 'peru', 'there', 'is', 'dictatorship', 'disguised', 'as', 'democracy'], ['fintech', 'peruana', 'tasatop', 'incursiona', 'en', 'mexico', 'para', 'captar', 'ahorristas', 'para', 'el', 'primer', 'ano', 'de', 'operaciones']]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "txt_free_url = remove_url(data)\n",
    "txt_free_threedot = remove_three_dots(txt_free_url)\n",
    "txt_free_breakline = remove_breakline(txt_free_threedot)\n",
    "txt_free_singlequotes = remove_single_quotes(txt_free_breakline)\n",
    "\n",
    "def texto_a_palabras(texto:str):\n",
    "    for sentencia in texto:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentencia), deacc=True))\n",
    "        \n",
    "data_palabras = list(texto_a_palabras(txt_free_singlequotes))\n",
    "\n",
    "print(data_palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(data_palabras, min_count=5, threshold=100)\n",
    "\n",
    "trigram = gensim.models.Phrases(bigram[data_palabras], threshold=100)\n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fintech', 'peruana', 'tasatop', 'incursiona', 'en', 'mexico', 'para', 'captar', 'ahorristas', 'para', 'el', 'primer', 'ano', 'de', 'operaciones']\n"
     ]
    }
   ],
   "source": [
    "print(bigram_mod[data_palabras[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['noto', 'prensar'], ['aytinoco', 'agravar', 'lesion', 'cuidar'], ['let', 'the', 'know', 'that', 'peru', 'there', 'dictatorship', 'disguised', 'democracy'], ['fintech', 'peruano', 'tasatop', 'incursionar', 'mexico', 'captar', 'ahorrista', '\\ufeff1', 'ano', 'operaci√≥n']]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in gensim.utils.simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "data_words_nostops = remove_stopwords(data_palabras)\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "nlp = spacy.load('es', disable=['parser', 'ner'])\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "print(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fintech',\n",
       " 'peruano',\n",
       " 'tasatop',\n",
       " 'incursionar',\n",
       " 'mexico',\n",
       " 'captar',\n",
       " 'ahorrista',\n",
       " '\\ufeff1',\n",
       " 'ano',\n",
       " 'operaci√≥n']"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lemmatized[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    " \n",
    "diccionario = corpora.Dictionary(data_lemmatized)\n",
    "#Corpus\n",
    "texto = data_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fintech', 'peruana', 'tasatop', 'incursiona', 'mexico', 'captar', 'ahorristas', 'primer', 'ano', 'operaciones']\n",
      "[(15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1)]\n"
     ]
    }
   ],
   "source": [
    "corpus = [diccionario.doc2bow(doc) for doc in texto]\n",
    "\n",
    "print(data_words_bigrams[3])\n",
    "print(corpus[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aytinoco', 'puedes', 'agravar', 'lesion', 'ten', 'cuidado']\n",
      "[(2, 1), (3, 1), (4, 1), (5, 1)]\n"
     ]
    }
   ],
   "source": [
    "print (data_words_bigrams[1])\n",
    "print (corpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('noto', 1), ('prensar', 1)],\n",
       " [('agravar', 1), ('aytinoco', 1), ('cuidar', 1), ('lesion', 1)],\n",
       " [('democracy', 1),\n",
       "  ('dictatorship', 1),\n",
       "  ('disguised', 1),\n",
       "  ('know', 1),\n",
       "  ('let', 1),\n",
       "  ('peru', 1),\n",
       "  ('that', 1),\n",
       "  ('the', 1),\n",
       "  ('there', 1)]]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(diccionario[id], freq) for id, freq in cp] for cp in corpus[0:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(list(diccionario.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correr y entrenar el modelo LDA sobre la matriz de t√©rminos.\n",
    "lda_model = gensim.models.LdaModel(corpus,\n",
    "                                   num_topics=20,\n",
    "                                   id2word = diccionario,\n",
    "                                   random_state=100,\n",
    "                                   passes=10,\n",
    "                                   update_every=1,\n",
    "                                   chunksize=100,\n",
    "                                   alpha='auto',\n",
    "                                   per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.040*\"fintech\" + 0.040*\"mexico\" + 0.040*\"ahorrista\" + 0.040*\"ano\" + 0.040*\"captar\" + 0.040*\"the\" + 0.040*\"incursionar\" + 0.040*\"tasatop\" + 0.040*\"peruano\" + 0.040*\"that\"\n",
      "\n",
      "Topic: 1 Word: 0.040*\"fintech\" + 0.040*\"mexico\" + 0.040*\"ahorrista\" + 0.040*\"ano\" + 0.040*\"captar\" + 0.040*\"the\" + 0.040*\"incursionar\" + 0.040*\"tasatop\" + 0.040*\"peruano\" + 0.040*\"that\"\n",
      "\n",
      "Topic: 2 Word: 0.093*\"ahorrista\" + 0.093*\"mexico\" + 0.093*\"tasatop\" + 0.093*\"peruano\" + 0.093*\"operaci√≥n\" + 0.093*\"Ôªø1\" + 0.093*\"incursionar\" + 0.093*\"fintech\" + 0.093*\"captar\" + 0.093*\"ano\"\n",
      "\n",
      "Topic: 3 Word: 0.040*\"fintech\" + 0.040*\"mexico\" + 0.040*\"ahorrista\" + 0.040*\"ano\" + 0.040*\"captar\" + 0.040*\"the\" + 0.040*\"incursionar\" + 0.040*\"tasatop\" + 0.040*\"peruano\" + 0.040*\"that\"\n",
      "\n",
      "Topic: 4 Word: 0.040*\"fintech\" + 0.040*\"mexico\" + 0.040*\"ahorrista\" + 0.040*\"ano\" + 0.040*\"captar\" + 0.040*\"the\" + 0.040*\"incursionar\" + 0.040*\"tasatop\" + 0.040*\"peruano\" + 0.040*\"that\"\n",
      "\n",
      "Topic: 5 Word: 0.040*\"fintech\" + 0.040*\"mexico\" + 0.040*\"ahorrista\" + 0.040*\"ano\" + 0.040*\"captar\" + 0.040*\"the\" + 0.040*\"incursionar\" + 0.040*\"tasatop\" + 0.040*\"peruano\" + 0.040*\"that\"\n",
      "\n",
      "Topic: 6 Word: 0.102*\"let\" + 0.102*\"dictatorship\" + 0.102*\"there\" + 0.102*\"the\" + 0.102*\"peru\" + 0.102*\"democracy\" + 0.102*\"that\" + 0.102*\"disguised\" + 0.102*\"know\" + 0.005*\"incursionar\"\n",
      "\n",
      "Topic: 7 Word: 0.040*\"fintech\" + 0.040*\"mexico\" + 0.040*\"ahorrista\" + 0.040*\"ano\" + 0.040*\"captar\" + 0.040*\"the\" + 0.040*\"incursionar\" + 0.040*\"tasatop\" + 0.040*\"peruano\" + 0.040*\"that\"\n",
      "\n",
      "Topic: 8 Word: 0.040*\"fintech\" + 0.040*\"mexico\" + 0.040*\"ahorrista\" + 0.040*\"ano\" + 0.040*\"captar\" + 0.040*\"the\" + 0.040*\"incursionar\" + 0.040*\"tasatop\" + 0.040*\"peruano\" + 0.040*\"that\"\n",
      "\n",
      "Topic: 9 Word: 0.323*\"prensar\" + 0.323*\"noto\" + 0.015*\"fintech\" + 0.015*\"ahorrista\" + 0.015*\"ano\" + 0.015*\"captar\" + 0.015*\"mexico\" + 0.015*\"tasatop\" + 0.015*\"peruano\" + 0.015*\"incursionar\"\n",
      "\n",
      "Topic: 10 Word: 0.040*\"fintech\" + 0.040*\"mexico\" + 0.040*\"ahorrista\" + 0.040*\"ano\" + 0.040*\"captar\" + 0.040*\"the\" + 0.040*\"incursionar\" + 0.040*\"tasatop\" + 0.040*\"peruano\" + 0.040*\"that\"\n",
      "\n",
      "Topic: 11 Word: 0.200*\"agravar\" + 0.200*\"aytinoco\" + 0.200*\"cuidar\" + 0.200*\"lesion\" + 0.010*\"incursionar\" + 0.010*\"tasatop\" + 0.010*\"captar\" + 0.010*\"fintech\" + 0.010*\"ahorrista\" + 0.010*\"mexico\"\n",
      "\n",
      "Topic: 12 Word: 0.040*\"fintech\" + 0.040*\"mexico\" + 0.040*\"ahorrista\" + 0.040*\"ano\" + 0.040*\"captar\" + 0.040*\"the\" + 0.040*\"incursionar\" + 0.040*\"tasatop\" + 0.040*\"peruano\" + 0.040*\"that\"\n",
      "\n",
      "Topic: 13 Word: 0.040*\"fintech\" + 0.040*\"mexico\" + 0.040*\"ahorrista\" + 0.040*\"ano\" + 0.040*\"captar\" + 0.040*\"the\" + 0.040*\"incursionar\" + 0.040*\"tasatop\" + 0.040*\"peruano\" + 0.040*\"that\"\n",
      "\n",
      "Topic: 14 Word: 0.040*\"fintech\" + 0.040*\"mexico\" + 0.040*\"ahorrista\" + 0.040*\"ano\" + 0.040*\"captar\" + 0.040*\"the\" + 0.040*\"incursionar\" + 0.040*\"tasatop\" + 0.040*\"peruano\" + 0.040*\"that\"\n",
      "\n",
      "Topic: 15 Word: 0.040*\"fintech\" + 0.040*\"mexico\" + 0.040*\"ahorrista\" + 0.040*\"ano\" + 0.040*\"captar\" + 0.040*\"the\" + 0.040*\"incursionar\" + 0.040*\"tasatop\" + 0.040*\"peruano\" + 0.040*\"that\"\n",
      "\n",
      "Topic: 16 Word: 0.040*\"fintech\" + 0.040*\"mexico\" + 0.040*\"ahorrista\" + 0.040*\"ano\" + 0.040*\"captar\" + 0.040*\"the\" + 0.040*\"incursionar\" + 0.040*\"tasatop\" + 0.040*\"peruano\" + 0.040*\"that\"\n",
      "\n",
      "Topic: 17 Word: 0.040*\"fintech\" + 0.040*\"mexico\" + 0.040*\"ahorrista\" + 0.040*\"ano\" + 0.040*\"captar\" + 0.040*\"the\" + 0.040*\"incursionar\" + 0.040*\"tasatop\" + 0.040*\"peruano\" + 0.040*\"that\"\n",
      "\n",
      "Topic: 18 Word: 0.040*\"fintech\" + 0.040*\"mexico\" + 0.040*\"ahorrista\" + 0.040*\"ano\" + 0.040*\"captar\" + 0.040*\"the\" + 0.040*\"incursionar\" + 0.040*\"tasatop\" + 0.040*\"peruano\" + 0.040*\"that\"\n",
      "\n",
      "Topic: 19 Word: 0.040*\"fintech\" + 0.040*\"mexico\" + 0.040*\"ahorrista\" + 0.040*\"ano\" + 0.040*\"captar\" + 0.040*\"the\" + 0.040*\"incursionar\" + 0.040*\"tasatop\" + 0.040*\"peruano\" + 0.040*\"that\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics():\n",
    "    print('Topic: {} Word: {}\\n'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreparedData(topic_coordinates=                                 x                            y  topics  \\\n",
      "topic                                                                     \n",
      "2         (0.24370260187549292+0j)    (-0.10435112387550298+0j)       1   \n",
      "6         (-0.2499075285833343+0j)    (-0.10247620396567092+0j)       2   \n",
      "11     (-0.0005392257190333801+0j)     (0.26790832089666655+0j)       3   \n",
      "9       (0.0022859199507890776+0j)   (-0.008694270235378098+0j)       4   \n",
      "8       (0.0002786395297552767+0j)  (-0.0032741701762571697+0j)       5   \n",
      "1       (0.0002786395297552685+0j)  (-0.0032741701762571836+0j)       6   \n",
      "3       (0.0002786395297552784+0j)  (-0.0032741701762571745+0j)       7   \n",
      "4       (0.0002786395297552778+0j)   (-0.003274170176257167+0j)       8   \n",
      "5      (0.00027863952975528886+0j)  (-0.0032741701762571654+0j)       9   \n",
      "7       (0.0002786395297552896+0j)  (-0.0032741701762571645+0j)      10   \n",
      "19      (0.0002786395297552981+0j)   (-0.003274170176257165+0j)      11   \n",
      "18     (0.00027863952975530236+0j)   (-0.003274170176257178+0j)      12   \n",
      "10      (0.0002786395297553007+0j)   (-0.003274170176257182+0j)      13   \n",
      "12       (0.000278639529755347+0j)  (-0.0032741701762571836+0j)      14   \n",
      "13      (0.0002786395297553205+0j)  (-0.0032741701762571767+0j)      15   \n",
      "14     (0.00027863952975533613+0j)  (-0.0032741701762571684+0j)      16   \n",
      "15      (0.0002786395297553538+0j)  (-0.0032741701762571784+0j)      17   \n",
      "16      (0.0002786395297553411+0j)   (-0.003274170176257203+0j)      18   \n",
      "17     (0.00027863952975525855+0j)  (-0.0032741701762571914+0j)      19   \n",
      "0      (0.00027863952975525855+0j)  (-0.0032741701762571914+0j)      20   \n",
      "\n",
      "       cluster       Freq  \n",
      "topic                      \n",
      "2            1  38.121147  \n",
      "6            1  34.139572  \n",
      "11           1  14.372447  \n",
      "9            1   6.725371  \n",
      "8            1   0.415091  \n",
      "1            1   0.415091  \n",
      "3            1   0.415091  \n",
      "4            1   0.415091  \n",
      "5            1   0.415091  \n",
      "7            1   0.415091  \n",
      "19           1   0.415091  \n",
      "18           1   0.415091  \n",
      "10           1   0.415091  \n",
      "12           1   0.415091  \n",
      "13           1   0.415091  \n",
      "14           1   0.415091  \n",
      "15           1   0.415091  \n",
      "16           1   0.415091  \n",
      "17           1   0.415091  \n",
      "0            1   0.415091  , topic_info=     Category      Freq          Term     Total  loglift  logprob\n",
      "term                                                             \n",
      "24    Default  1.000000            Ôªø1  1.000000  25.0000  25.0000\n",
      "23    Default  1.000000       tasatop  1.000000  24.0000  24.0000\n",
      "22    Default  1.000000       peruano  1.000000  23.0000  23.0000\n",
      "21    Default  1.000000     operaci√≥n  1.000000  22.0000  22.0000\n",
      "20    Default  1.000000        mexico  1.000000  21.0000  21.0000\n",
      "19    Default  1.000000   incursionar  1.000000  20.0000  20.0000\n",
      "18    Default  1.000000       fintech  1.000000  19.0000  19.0000\n",
      "17    Default  1.000000        captar  1.000000  18.0000  18.0000\n",
      "16    Default  1.000000           ano  1.000000  17.0000  17.0000\n",
      "15    Default  1.000000     ahorrista  1.000000  16.0000  16.0000\n",
      "13    Default  1.000000           the  1.000000  15.0000  15.0000\n",
      "14    Default  1.000000         there  1.000000  14.0000  14.0000\n",
      "12    Default  1.000000          that  1.000000  13.0000  13.0000\n",
      "11    Default  1.000000          peru  1.000000  12.0000  12.0000\n",
      "10    Default  1.000000           let  1.000000  11.0000  11.0000\n",
      "9     Default  1.000000          know  1.000000  10.0000  10.0000\n",
      "8     Default  1.000000     disguised  1.000000   9.0000   9.0000\n",
      "7     Default  1.000000  dictatorship  1.000000   8.0000   8.0000\n",
      "6     Default  1.000000     democracy  1.000000   7.0000   7.0000\n",
      "5     Default  0.000000        lesion  0.000000   6.0000   6.0000\n",
      "4     Default  0.000000        cuidar  0.000000   5.0000   5.0000\n",
      "3     Default  0.000000      aytinoco  0.000000   4.0000   4.0000\n",
      "2     Default  0.000000       agravar  0.000000   3.0000   3.0000\n",
      "1     Default  0.000000       prensar  0.000000   2.0000   2.0000\n",
      "0     Default  0.000000          noto  0.000000   1.0000   1.0000\n",
      "24     Topic1  0.889493            Ôªø1  1.057628   0.7913  -2.3716\n",
      "23     Topic1  0.889493       tasatop  1.057628   0.7913  -2.3716\n",
      "22     Topic1  0.889493       peruano  1.057628   0.7913  -2.3716\n",
      "21     Topic1  0.889493     operaci√≥n  1.057628   0.7913  -2.3716\n",
      "20     Topic1  0.889493        mexico  1.057628   0.7913  -2.3716\n",
      "...       ...       ...           ...       ...      ...      ...\n",
      "19    Topic19  0.004151   incursionar  1.057628  -0.0560  -3.2189\n",
      "20    Topic19  0.004151        mexico  1.057628  -0.0560  -3.2189\n",
      "21    Topic19  0.004151     operaci√≥n  1.057628  -0.0560  -3.2189\n",
      "22    Topic19  0.004151       peruano  1.057628  -0.0560  -3.2189\n",
      "24    Topic19  0.004151            Ôªø1  1.057628  -0.0560  -3.2189\n",
      "0     Topic20  0.004151          noto  0.727828   0.3177  -3.2189\n",
      "1     Topic20  0.004151       prensar  0.727828   0.3177  -3.2189\n",
      "2     Topic20  0.004151       agravar  0.894894   0.1110  -3.2189\n",
      "3     Topic20  0.004151      aytinoco  0.894894   0.1110  -3.2189\n",
      "4     Topic20  0.004151        cuidar  0.894894   0.1110  -3.2189\n",
      "5     Topic20  0.004151        lesion  0.894894   0.1110  -3.2189\n",
      "11    Topic20  0.004151          peru  1.043164  -0.0423  -3.2189\n",
      "6     Topic20  0.004151     democracy  1.043164  -0.0423  -3.2189\n",
      "7     Topic20  0.004151  dictatorship  1.043164  -0.0423  -3.2189\n",
      "8     Topic20  0.004151     disguised  1.043164  -0.0423  -3.2189\n",
      "9     Topic20  0.004151          know  1.043164  -0.0423  -3.2189\n",
      "10    Topic20  0.004151           let  1.043164  -0.0423  -3.2189\n",
      "12    Topic20  0.004151          that  1.043164  -0.0423  -3.2189\n",
      "13    Topic20  0.004151           the  1.043164  -0.0423  -3.2189\n",
      "14    Topic20  0.004151         there  1.043164  -0.0423  -3.2189\n",
      "23    Topic20  0.004151       tasatop  1.057628  -0.0560  -3.2189\n",
      "15    Topic20  0.004151     ahorrista  1.057628  -0.0560  -3.2189\n",
      "16    Topic20  0.004151           ano  1.057628  -0.0560  -3.2189\n",
      "17    Topic20  0.004151        captar  1.057628  -0.0560  -3.2189\n",
      "18    Topic20  0.004151       fintech  1.057628  -0.0560  -3.2189\n",
      "19    Topic20  0.004151   incursionar  1.057628  -0.0560  -3.2189\n",
      "20    Topic20  0.004151        mexico  1.057628  -0.0560  -3.2189\n",
      "21    Topic20  0.004151     operaci√≥n  1.057628  -0.0560  -3.2189\n",
      "22    Topic20  0.004151       peruano  1.057628  -0.0560  -3.2189\n",
      "24    Topic20  0.004151            Ôªø1  1.057628  -0.0560  -3.2189\n",
      "\n",
      "[525 rows x 6 columns], token_table=      Topic      Freq          Term\n",
      "term                               \n",
      "2         3  1.117450       agravar\n",
      "15        1  0.945512     ahorrista\n",
      "16        1  0.945512           ano\n",
      "3         3  1.117450      aytinoco\n",
      "17        1  0.945512        captar\n",
      "4         3  1.117450        cuidar\n",
      "6         2  0.958622     democracy\n",
      "7         2  0.958622  dictatorship\n",
      "8         2  0.958622     disguised\n",
      "18        1  0.945512       fintech\n",
      "19        1  0.945512   incursionar\n",
      "9         2  0.958622          know\n",
      "5         3  1.117450        lesion\n",
      "10        2  0.958622           let\n",
      "20        1  0.945512        mexico\n",
      "0         4  1.373950          noto\n",
      "21        1  0.945512     operaci√≥n\n",
      "11        2  0.958622          peru\n",
      "22        1  0.945512       peruano\n",
      "1         4  1.373950       prensar\n",
      "23        1  0.945512       tasatop\n",
      "12        2  0.958622          that\n",
      "13        2  0.958622           the\n",
      "14        2  0.958622         there\n",
      "24        1  0.945512            Ôªø1, R=25, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 7, 12, 10, 9, 2, 4, 5, 6, 8, 20, 19, 11, 13, 14, 15, 16, 17, 18, 1])\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model,corpus,diccionario)\n",
    "print(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#leemos los archivos de palabras positivas y negativas\n",
    "positivas = pd.read_csv('DataPolaridad/up_positivas.csv', encoding = 'utf-8').Palabra.tolist()\n",
    "negativas = pd.read_csv('DataPolaridad/up_negativas.csv', encoding = 'utf-8').Palabra.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sentiment(list_palabra):\n",
    "    sent = {'positivos':0, 'negativos':0}\n",
    "    for word in list_palabra:\n",
    "        if word in positivas:\n",
    "            sent['positivos'] = sent['positivos'] + 1\n",
    "        elif word in negativas:\n",
    "            sent['negativos'] = sent['negativos'] + 1\n",
    "        else:\n",
    "            pass\n",
    "    if sent['positivos'] > sent['negativos']:\n",
    "        return 'positivo'\n",
    "    elif sent['positivos'] < sent['negativos']:\n",
    "        return 'negativo'\n",
    "    else:\n",
    "        return 'neutro'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['nota', 'prensa'], ['aytinoco', 'puedes', 'agravar', 'lesion', 'ten', 'cuidado'], ['let', 'the', 'world', 'know', 'that', 'in', 'peru', 'there', 'is', 'dictatorship', 'disguised', 'as', 'democracy'], ['fintech', 'peruana', 'tasatop', 'incursiona', 'mexico', 'captar', 'ahorristas', 'primer', 'ano', 'operaciones']]\n"
     ]
    }
   ],
   "source": [
    "#Analizamos las frases o tweets de Twitter.\n",
    "print(data_words_nostops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: ['nota', 'prensa']\n",
      "Ranking: neutro\n",
      "\n",
      "Topic: ['aytinoco', 'puedes', 'agravar', 'lesion', 'ten', 'cuidado']\n",
      "Ranking: negativo\n",
      "\n",
      "Topic: ['let', 'the', 'world', 'know', 'that', 'in', 'peru', 'there', 'is', 'dictatorship', 'disguised', 'as', 'democracy']\n",
      "Ranking: neutro\n",
      "\n",
      "Topic: ['fintech', 'peruana', 'tasatop', 'incursiona', 'mexico', 'captar', 'ahorristas', 'primer', 'ano', 'operaciones']\n",
      "Ranking: neutro\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for palabraTweet in data_words_nostops[0:10]:\n",
    "    print('Topic: {}\\nRanking: {}\\n'.format(palabraTweet, get_sentiment(palabraTweet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: ['nota', 'prensa']\n",
      "Ranking: neutro\n",
      "\n",
      "Topic: ['aytinoco', 'puedes', 'agravar', 'lesion', 'ten', 'cuidado']\n",
      "Ranking: negativo\n",
      "\n",
      "Topic: ['let', 'the', 'world', 'know', 'that', 'in', 'peru', 'there', 'is', 'dictatorship', 'disguised', 'as', 'democracy']\n",
      "Ranking: neutro\n",
      "\n",
      "Topic: ['fintech', 'peruana', 'tasatop', 'incursiona', 'mexico', 'captar', 'ahorristas', 'primer', 'ano', 'operaciones']\n",
      "Ranking: neutro\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for palabraTweet in data_words_nostops[0:10]:\n",
    "    print('Topic: {}\\nRanking: {}\\n'.format(palabraTweet, get_sentiment(palabraTweet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
